---
title: "BIO00066I Workshop 2"
subtitle: "Cell Biology Data Analysis Workshop 2"

author: Daniel Jeffares
date: 2024-01-25
format:
    html:
        code-link: true
        toc: true
        number-sections: true
        toc-location: right
        toc-depth: 2
        
editor: source
---

**Colour scheme**

In these workshops, we highlight some elements in boxes like this:

::: callout-important
## Important concepts

Particularly important ideas or skills.
:::

::: callout-warning
## Be careful

Where to be careful.
:::

::: callout-tip
## Things to think about

What does this result show about the biology?
:::

::: callout-note
## Information

[Mesenchymal stem cells](https://en.wikipedia.org/wiki/Mesenchymal_stem_cell) are multipotent, but not pluripotent.
:::

# Learning objectives

In this workshop, you will learn ***technical skills*** and ***data science concepts***.

**Technical skills**

-   RStudio skills to manage, view and analyse large data sets
-   How to create plots in RStudio to assist with exploring and interpreting data
-   How to make your data analysis reproducible and well-explained

**Thinking like a data scientist**

-   How to interpret data with care
-   How to integrate knowledge from laboratory work and computational analysis

# Introduction

::: callout-important
## Philosophy

Workshops are not a test. It's OK to make mistakes. It's OK to need help. You should be familiar with independent study content before the workshop, but you don't need to understand **every detail**. The workshop will hlpe you to build and consolidate your understanding. Tips:

-   there are **no stupid questions** (ask us anything!)
-   don't worry about making mistakes (we all make mistakes)
-   discuss code with your neighbours and with the staff
-   outside of workshop times, google is a good resource
:::

## The biology

Today we will look at some data from mesenchymal stem cells (MSCs, sometimes called stromal cells). MCSs are are *multipotent* stem cells, than can differentiate into many kinds of mesenchymal cells: bone, cartilage and fat cells. They are not *pluripotent*, in that they do have limits about how they differentiate.

MSCs are also:

-   immuno-modulatory (they make cytokines)
-   heterogeneous (they have subpopulations that are different from each other)

**The MSCs we are looking at** are from bone marrow femoral head tissues (from the hip bone). These MSCs were *immortalised* (by XXX), and then cloned by limiting dilution. We will compare the data on cell shape and size from just **two clones**, both obtained from one person's femoral head tissues. Each *clone* was derived from a *single cell* from the person.

We call these two clones *clone A* and *clone B*. Today, we will use our data analysis skills to explore how these cells differ.

## Research questions

1.  What parameters do we have in the data obtained from the XXX machine/method?
2.  Which parameters differ between the clones?
3.  Which parameters are correlated?

## The data

The data we have today are derived from an XXX machine. We grew each clones in XXX media, and captured cell shape an size information for many cells from each clones with XXX machine. For each clone, we measured three *biological replicates*.

::: callout-note
## Biological replicates and technical replicates

**A biological replicate** repeats an experiment from different cell types, tissue types, or organisms to see if similar results can be observed.

**Technical replicates** are repeat measurements of *the same biological material*, which help to show how much variation comes from the equipment or different methods (rather from the biology).

Our replicates are almost *biological replicates*, because we grew the cells three times.
:::

::: callout-important
## Thinking like a data scientist

Data science can be challenging when you first start. But data science does have core concepts, like any other science.

-   Consider the motivation or scientific question *before* drawing a plot
-   Reflect on how the plot or analysis addresses the scientific question
-   Use each plots to adapt, to inspire new research questions and new inquiries
-   Ensure that your scripts are reproducible and clearly commented
-   **Consider what the results tell you about the biology**
:::

# Exercises

## Getting started

1.  Start RStudio from the Start menu
2.  Open your RStudio project using the dropdown menu at the very **top right** of the RStudio window.
3.  Make a new script then save it with a sensible name that will help you to know later what is in this file. `BIO00066I-workshop2.R` would work.
4.  Add a comment to the script so you know what it is about, for example

```{r}
#Data Analysis 2: Cell Biology
#date 2024-30-01
```

5.  Clear all the previous data, and load **`tidyverse`** package by adding these lines to your script:

```{r}
#| echo: true
#| warning: false
#| eval: true

#clear previous data
rm(list=ls())

#load the tidyverse
library(tidyverse)

```

6.  Finally load another library that allows us to make multi-part plots (this can be useful sometimes). #we need this to make pretty plots with the 'ggarrange' package

```{r}
#| echo: true
#| warning: false
#| eval: true

#load the ggpubr package for multi-part plots
library(ggpubr)
```

7.  Make sure all these lines of code are in your script, with comments.
8.  Save the script.

::: callout-important
## Comment your code!

In R scripts, lines that start with the hash symbol (`#`) are comments.

Commenting code makes it readable, for you and anyone else. Good data science includes clearly commented code.
:::

## Loading the data

In workshop 1, we showed you how to [import data from files](https://3mmarand.github.io/R4BABS/r4babs1/week-8/workshop.html#importing-data-from-files). Today, we load a tab-separated value (TSV) file from a website:

```{r}
#| echo: true
#| warning: false
cells <-read_tsv("data/all-cell-data-FFT.filtered.2024-01-19.tsv",
    col_types = cols(
        clone = col_factor(),
        replicate = col_factor(),
        tracking.id=col_factor(),
        lineage.id=col_factor()
    )
)
```

::: callout-note
## About read_tsv

We use the `read_tsv` function to read the tab-separated value file. Clicking on the link in the `read_tsv` takes you to a website about this function. **All the code chunks in these workshops have links like this.**

The `clone = col_factor(),replicate = col_factor()` part let's R know that we want the *clone* column and the *replicate* column to be factors, rather than numeric values. Factors are used to represent categorical data.
:::

## Exploring the data

It is important to know what data you have. How many rows and columns *etc*.

There are many ways to do this in R. Here are some of our favourites. Copy and past these into your R script, and try them out.

##Amanda: should we remove some of the less-useful columns? #This will keep it simple for the students #Are the different measurements of cell size & shape *independent* measures?

```{r}
#| echo: true
#| warning: false
#| output: false

#look at the data, like an excel table:
view(cells)

#what are the names of the columns?
names(cells)

#how many rows and columns you we have?
nrow(cells)
ncol(cells)
dim(cells)

#other ways to peek at data:
summary(cells)
glimpse(cells)
```

::: callout-tip
# Which method of do *you* like the best?

Why not take a note of this, and use it all the time?
:::

### What is in the data?

You may have noticed that we have two clones (cloneA and cloneB). For each clone, we have three replicates. For each replicate, we have many readings of cell widths, cell volume, cell sphericity and so on.

**Now save your data and save your script.** This command will save **all** the variables you have loaded, or created so far:

```{r}
#| echo: true
#| warning: false
#| output: false
#save all my stuff
save.image("BIO00066I-workshop2.Rda")
```

You can load all the data again with:

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false
#load all my stuff from last time
load("BIO00066I-workshop2.Rda")
```

## Summarise with dplyr

The `view(cells)` command shows that we have many cell shape metrics. We saw a summary of our cell shape metrics with the `summary(cells)` command above.

Now we will do something even better, by using a tool from the `dplyr` package (part of the `tidyverse`) to make some sense of all this data very quickly.

::: callout-note
## dplyr is wonderful

`dplyr` is like a set of pliers, helping us to 'bend' or 'reshape' our data.
:::

Here is the command. I will explain it below.

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: true
summary.table <- cells |> 
    group_by(clone, replicate) |> 
    summarise(
        volume=median(volume),
        mean.thickness=median(mean.thickness),
        radius=median(radius),
        area=median(area),
        sphericity=median(sphericity),
        length=median(length),
        dry.mass=median(dry.mass),
        perimeter=median(perimeter),
        length.to.width=median(length.to.width)
)
```

### What this code does

-   The `cells |>` part takes the data from the `cells` data frame, and 'pipes' it into the `group_by` function. The `|>` symbol as means **put this data into the next bit**.

-   `group_by(clone, replicate)` means that make groups of data, according to which clone they are, and which replicate culture they were from.

-   `summarise` calculates some summaries of all the data rows (for each clone and replicate). The part `volume=median(volume)` creates a header called `volume` and fills this with the median cell volume for each clone and replicate

-   Right at the top, `summary.table <-` stores the results of all the piping in an object called `summary.table`.

Have a look at the information we generated with:

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false

view(summary.table)
```

::: callout-tip
## Do you see any patterns in this data?

-   What does this table tell you about **clone A** and **clone B**?
-   What does this tell you about mesenchymal stem cells?
:::

------------------------------------------------------------------------

## Making plots

It looks like many of the cell shape metrics from above might differ between clones. So let's look deeper, starting with `cell width`. We will make a box and whisker plot. We use a small 'trick' here: by including `fill=replicate` we force R to make different plots for each replicate.

```{r}
ggplot(cells,aes(x=clone,y=width,fill=replicate))+
    geom_boxplot()
```

::: callout-important
## Making plots with ggplot

No matter what shape plot you want, `ggplot` uses the same syntax.

1.  Start by telling R what data you want to use like this: `ggplot(some_data_frame,aes(x=x_axis_data, y=y_axis_data) +`

In this line, `x_axis_data` and `y_axis_data` are columns of some_data_frame.

2.  Then define what the shape plot you want (the 'geometry'): `geom_boxplot()`, `geom_histogram()` etc.
3.  Add extra things to customise your plot, eg: `xlab("my x axis label")`

If you are unsure what to do, it's OK to ask! Googling "ggpplot how to make a boxplot" (or any other plot) will help.
:::

It does look like clone A and clone B differ consistently in width, with all repeats. To prove this, we would like to do a statistical test. A Student's t-Test `t.test` would work. But t-Test's assume that the data are normally distributed (like a bell curve).

We can test this approximately by plotting data, as below. It doesn't look perfectly 'bell shaped', so let's play is safe and use a nonparametric test.

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false

ggplot(cells, aes(x = width)) +
  geom_density()

```

The nonparametric equivalent of a t-Test is a **Wilcoxon rank sum test**. There are two ways to run this test in R. We can do `wilcox.test(vectorA, vectorB)`, where vectorA and vectorB contain the numeric values we want to test.

But does does not suit `tidyverse` data frames very well. So we will use the `wilcox.test(numberic_value ~ categorry_name, data = some_data_frame)` method, like so:

```{r}
#Wilcoxon rank sum test
#To test if cloneA and cloneB have statistically different widths
wilcox.test(width ~ clone, data = cells)
```

Because the `p-value` is *very low* (\< 2.2e-16), this means the null hypothesis (that both sets of numbers come from the same population) is *very* unlikely to be true.

::: callout-warning
## Non-parametric tests are safe

Parametric tests are based on assumptions about the distribution of the real data. Nonparametric statistics are not based on these assumptions. So they are safer. Many biological metrics need nonparametric tests.
:::

### An easier way

Fortunately, you can add the results of nonparametric tests to ggplot, by adding `stat_compare_means()` to our plot. Note that below we do not force R to split up the replicates as we did above.

```{r}
ggplot(cells,aes(x=clone,y=width))+
    geom_boxplot()+
    stat_compare_means()
```

# Next step: modify the code

::: callout-important
## If there is something you don't uderstand, it's OK to ask us!
:::

To increase your understanding, run through all the plots in section 3.5 with some other cell shape or size metric.

To start, find what metrics are present with:

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false

names(cells)
```

We suggest using one of these, in place of `width`:

-   volume
-   mean.thickness
-   radius
-   area
-   sphericity
-   length
-   dry.mass

# Analysis with small data

So far, we have used **all** the rows in our data frame. But perhaps, this isn't wise, because the Livecyte tracking followed each cell over time. So each measurement of cell shape is not a *completely* an independent measurement.It is more of a technical replicate than a biological replicate. It is valuable to learn how to make plots and analyse small data sets, as well as large ones. So not we will create a very small subset of the data, and investigate this.

# Reflection

-   After loading the data, what did we do first?
-   What did making the plots do that summary statistics (liek average, or median) cannot do?
-   What did we learn about the two clones?

# After the workshop

Look at your script again. Add some comments, so that the next time you look at it, it will make more sense to you.

Also, have a go at the consolidation exercises below.

## Consolidation exercises

### Violin plots `geom_violin`

1.  We used `geom_boxplot()`to show the differences between categories (clone A and clone B). Try `geom_violin` instead. Which one do you prefer?

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false

ggplot(cells,aes(x=clone,y=width,fill=replicate))+
    geom_violin()
```

2.  Now adjust the title with `ggtitle(label)`, and the axis labels with `xlab(label)` and `ylab(label)`, and the **theme** (the general style of the plot), with `theme_classic()`. Use whatever theme you feel makes the data clear.

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false
ggplot(cells,aes(x=clone,y=length,fill=replicate))+
    geom_violin()+
    ggtitle("something")+
    xlab("clone")+
    ylab("length")+
    theme_classic()

```


::: callout-tip
# Learning a small amount regularly is better than cramming.
Because our brains can only concentrate for a short time.
:::

### Making the small data set

This is how we made the small data set `trackingid.small.data`. Reading through and/or trying out this code will enhance your skills.

Use the `dplyr` tools `group_by` and `summarise` to calculate the average of all the cell shape measurements for each cell. Each cell is marked by the Livecyte software with a tracking id (`tracking.id`), so we group cells by this. The code `group_by(clone, replicate, tracking.id)` will group each measurement by the clone, replicate **and** tracking id, then the `summarise` part calculates the mean values for all our metrics:

```{r}
#take the mean of each unique tracking id
trackingid.summary.table<-cells |>
    group_by(clone, replicate, tracking.id) |>
    summarise(
        volume=median(volume),
        mean.thickness=median(mean.thickness),
        radius=median(radius),
        area=median(area),
        sphericity=median(sphericity),
        length=median(length),
        dry.mass=median(dry.mass),
        perimeter=median(perimeter),
        length.to.width=median(length.to.width)
    )
```

Then we use the `dplyr` function `sample_n`, which samples a number of rows from a data frame at random. If the data frame is grouped (which our data is), the number we set applies to each group:

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: true

#collect a random subset, of 5 rows for each tracking id
trackingid.small.data <- sample_n(trackingid.summary.table, 5)

#check that we have
nrow(trackingid.small.data)
glimpse(trackingid.small.data)
```


We write the output to a file:

```{r}
#output trackingid.small.data as a tab-separated value (tsv) file
write_tsv(trackingid.small.data, file ="/Users/dj757/gd/modules/BIO66I/data/trackingid.small.data.tsv")
```

Look at the `trackingid.small.data` data frame, so we know what we have:

```{r}
#| echo: true
#| warning: false
#| output: false
#| eval: false

#how many rows do we have?
nrow(trackingid.small.data)

#what does the data look like?
view(trackingid.small.data)
```


## Planning for your report



# The end.

